<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>List of posts on Everyday Linux</title>
    <link>https://briantward.github.io/posts/</link>
    <description>Recent content in List of posts on Everyday Linux</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Mar 2020 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://briantward.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>CoreDNS Custom DNS Running on OpenShift</title>
        <link>https://briantward.github.io/coredns-nonprivileged/</link>
        <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/coredns-nonprivileged/</guid>
        <description>CoreDNS Custom DNS Running on OpenShift This example provides the bare requirements for deploying a custom DNS server on OpenShift using the default restricted SCC profile, which means that the pod is run without privileges as a nonroot user. This should work fine on both OpenShift 3.11 and 4.x.
 You can edit this dns-config ConfigMap as necessary to modify the DNS zone records as you need.
 $ echo &#39;apiVersion: v1 data: Corefile: | example.</description>
      </item>
    
      <item>
        <title>An Introduction to Running Java on Kubernetes</title>
        <link>https://briantward.github.io/running-java-on-kubernetes/</link>
        <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/running-java-on-kubernetes/</guid>
        <description>An Introduction to Running Java on Kubernetes You will need access to a container build tool, a container runtime environment, and a kubernetes environment. There will be suggestions along the way for acquiring these. You will need a virtualization technology to run the minikube or minishift VMs for your kubernetes development environment.
   Build a Demo Spring Boot App  Build an app
$ mkdir -p my-java-app/container $ cd my-java-app $ git clone https://github.</description>
      </item>
    
      <item>
        <title>RHVH Ovirt</title>
        <link>https://briantward.github.io/rhvh-ovirt/</link>
        <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rhvh-ovirt/</guid>
        <description>RHVH Ovirt I&amp;#8217;m not an infra dedicated person. So I don&amp;#8217;t have a ton of experience in using multipath. But Red Hat documentation is pretty thorough on the subject.[1][2]
 There is even this KCS that discusses the matter a little more: Internal disk device is being detected as multipath device
 In setting up my bare metal servers for RHVH, after adding all my disks to the system as basically single RAID 0 disks, I found that the base image for RHVH had particular settings for creating a single path multipath entry for these.</description>
      </item>
    
      <item>
        <title>bash Tips</title>
        <link>https://briantward.github.io/bash-tips/</link>
        <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/bash-tips/</guid>
        <description>Command Tips String the watch command with several commands at once
 watch &#39;command | othertool | yet-another-tool&#39;   https://unix.stackexchange.com/questions/318859/how-to-use-watch-command-with-a-piped-chain-of-commands-programs
 This one is useful when you don&amp;#8217;t have a user directory on the system yet.
 /sbin/mkhomedir_helper &amp;lt;username&amp;gt; [&amp;lt;umask&amp;gt; [&amp;lt;skeldir&amp;gt;]]   https://serverfault.com/questions/63764/create-home-directories-after-create-users
   </description>
      </item>
    
      <item>
        <title>SSH Tips</title>
        <link>https://briantward.github.io/ssh-tips/</link>
        <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/ssh-tips/</guid>
        <description>SSH Tips SSH Tunnel $ ssh user@remote-host -L 9993:remote-host:9993    SSH Keyen $ ssh-keygen -t rsa -b 4096 -C &#34;email organization&#34;    SSH-Forwarding Like this guy&amp;#8217;s example. After using nc for years, ProxyJump is now very useful!
 Host forum HostName www.nixcraft.com ProxyJump vivek@jumhost.nixcraft.com:22 User vivek   https://www.cyberciti.biz/faq/linux-unix-ssh-proxycommand-passing-through-one-host-gateway-server/
  ForwardAgent I&amp;#8217;m not truly certain about the security implications of using ForwardAgent, but this article does suggest there are some issues.</description>
      </item>
    
      <item>
        <title>Expand a Qemu Disk</title>
        <link>https://briantward.github.io/expand-qemu-disk/</link>
        <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/expand-qemu-disk/</guid>
        <description>Expand a Qemu Disk I exhausted the disk space on my Windows VM and found I needed more room. This is one of those lovely tasks that actually has simple and good documentation and works easily enough.
 I followed these instructions using qemu-resize:
 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/sect-using_qemu_img-re_sizing_the_disk_image
 But you might find this just as helpful:
 https://maunium.net/blog/resizing-qcow2-images/
 Here is another read on using virt-resize instead of qemu-resize but a little more to it:</description>
      </item>
    
      <item>
        <title>Build A Router</title>
        <link>https://briantward.github.io/build-a-router/</link>
        <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/build-a-router/</guid>
        <description>Build A Router on Red Hat Enterprise Linux 7 This provided a nice resource for reference.[1] I will elaborate a litte more here. I wanted to set up a custom router to the internet, to provide advanced firewall and logging features. Note that this example does not provide DHCP services. In my case, I have a secondary off-the-shelf (OTS) router doing that. Since the OTS router did not offer advanced firewall, NAT, port-forwarding, and such features, I decided to build my own.</description>
      </item>
    
      <item>
        <title>Bridged Host-VM Network</title>
        <link>https://briantward.github.io/bridge-host-vm/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/bridge-host-vm/</guid>
        <description>Bridged Host-VM Network     Host OS:
 Red Hat Enterprise Linux 7.5, may also work on other RHEL-based variants
   Host Virtual Platform:
 virt-manager, virsh, libvirt, qemu
   Guest OS:
 Any
    Setup a bridged network connection on RHEL 7.5 using Network Manager so that a VM can reside on the same network as the host.
 e.g.</description>
      </item>
    
      <item>
        <title>Create Root Access from any Build in OpenShift</title>
        <link>https://briantward.github.io/openshift-root-access-on-build/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-root-access-on-build/</guid>
        <description>Create Root Access from any Build in OpenShift TODO: split examples, show DC options
 This example adds an SCC permission to run root on the default service account, allowing you to run root containers. This is not recommended for normal practice and should only be done during troubleshooting, on an isolated nonprod worker node. You could also choose to create a service account specific to this one application and configure the DeploymentConfig to use that (this is not shown here).</description>
      </item>
    
      <item>
        <title>Docker Core Dumps</title>
        <link>https://briantward.github.io/docker-core-dump/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/docker-core-dump/</guid>
        <description>Docker Core Dumps  Get the container id (CID) of the pod to be checked. From the node running the pod. You will need to be able to identify your container ID.
# docker ps # CID=xxx     Check if docker is logging
# docker logs &amp;lt;CID&amp;gt;     Check node&amp;#8217;s journal
# journalctl CONTAINER_ID=&amp;lt;CID&amp;gt;     Grab lsof and gcore for each process: dockerd-current, docker-containerd-current, and docker-containerd-shim-current.</description>
      </item>
    
      <item>
        <title>MiniShift Tips</title>
        <link>https://briantward.github.io/minishift-tips/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/minishift-tips/</guid>
        <description>MiniShift Tips hard cleanup minishift environment For example, for errors such as
 domain &#39;minishift&#39; already exists with uuid    Check if the VM is still running
$ sudo virsh list --all     If it is running, stop the minishift VM
$ sudo virsh destroy minishift     Delete the VM
$ sudo virsh undefine minishift     Delete the .minishift/machines dir</description>
      </item>
    
      <item>
        <title>OpenShift Application Core Dumps</title>
        <link>https://briantward.github.io/openshift-application-coredumps/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-application-coredumps/</guid>
        <description>OpenShift Application Core Dumps When logs fail to provide us the information we need to diagnose an application problem, we may find it useful to take core dumps of memory, showing us the processes as they are currently running in the system. This is not something we want to do on a regular basis in production. Ideally such problems are discovered during application performance and load testing in lower environments. In reality we frequently find something unique about the real-world application load that our test scenarios could never uncover.</description>
      </item>
    
      <item>
        <title>OpenShift Firewall</title>
        <link>https://briantward.github.io/openshift-firewall/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-firewall/</guid>
        <description>OpenShift Firewall To add a firewall entry on 3.x, where the firewall installed was iptables rather than firewalld
 iptables -A OS_FIREWALL_ALLOW -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT     </description>
      </item>
    
      <item>
        <title>OpenShift Router Quick Links</title>
        <link>https://briantward.github.io/openshift-router/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-router/</guid>
        <description>OpenShift Router quick links router balancing
 router environment variables
   https://docs.openshift.com/container-platform/3.7/architecture/networking/routes.html#env-variables
  https://docs.openshift.com/container-platform/3.6/architecture/networking/routes.html#load-balancing
  https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html#route-specific-annotations
  https://docs.openshift.com/container-platform/3.7/architecture/networking/routes.html#routes-sticky-sessions
  https://docs.openshift.com/container-platform/3.7/dev_guide/routes.html#dev-guide-routes-allowing-endpoints-to-control-cookies
   passthrough
   https://github.com/openshift/origin/commit/a4815c6314f9df1d2ce8060216d0924181c48b6c
Changed the router default to roundrobin if non-zero weights are used
https://bugzilla.redhat.com/show_bug.cgi?id=1416869
   stick sessions in haproxy
   https://www.haproxy.com/blog/load-balancing-affinity-persistence-sticky-sessions-what-you-need-to-know/
  http://www.haproxy.org/download/1.8/doc/configuration.txt (3.11)
   kubernetes service
   https://kubernetes.io/docs/concepts/services-networking/service/</description>
      </item>
    
      <item>
        <title>RH-SSO Filter Examples</title>
        <link>https://briantward.github.io/rh-sso-filter-examples/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rh-sso-filter-examples/</guid>
        <description>RH-SSO Filter Examples This Undertow filter prevents certain IP addresses from access resources on the server.
  &amp;lt;subsystem xmlns=&#34;urn:jboss:domain:undertow:3.1&#34;&amp;gt; &amp;lt;buffer-cache name=&#34;default&#34;/&amp;gt; &amp;lt;server name=&#34;default-server&#34;&amp;gt; &amp;lt;http-listener name=&#34;default&#34; socket-binding=&#34;http&#34; redirect-socket=&#34;https&#34;/&amp;gt; &amp;lt;https-listener name=&#34;https&#34; record-request-start-time=&#34;true&#34; security-realm=&#34;CertificateRealm&#34; socket-binding=&#34;https&#34;/&amp;gt; &amp;lt;host name=&#34;default-host&#34; alias=&#34;localhost&#34;&amp;gt; &amp;lt;location name=&#34;/&#34; handler=&#34;welcome-content&#34;/&amp;gt; &amp;lt;access-log pattern=&#34;%{i,X-Forwarded-For} %h %l %u %t &amp;amp;quot;%r&amp;amp;quot; %s %b &amp;amp;quot;%{i,Referer}&amp;amp;quot; &amp;amp;quot;%{i,User-Agent}&amp;amp;quot; &amp;amp;quot;%{i,COOKIE}&amp;amp;quot; &amp;amp;quot;%{o,SET-COOKIE}&amp;amp;quot; %S &amp;amp;quot;%I&amp;amp;quot; %T&#34;/&amp;gt; &amp;lt;filter-ref name=&#34;my-proxy-peer-address&#34; predicate=&#34;equals(%p,8443)&#34;/&amp;gt; &amp;lt;filter-ref name=&#34;kc-account-update-reject&#34;/&amp;gt; &amp;lt;filter-ref name=&#34;kc-admin-reject&#34;/&amp;gt; &amp;lt;/host&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;servlet-container name=&#34;default&#34;&amp;gt; &amp;lt;jsp-config/&amp;gt; &amp;lt;websockets/&amp;gt; &amp;lt;/servlet-container&amp;gt; &amp;lt;handlers&amp;gt; &amp;lt;file name=&#34;</description>
      </item>
    
      <item>
        <title>Rsync Tips</title>
        <link>https://briantward.github.io/rsync-tips/</link>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rsync-tips/</guid>
        <description>Rsync Tips   Be careful with trailing slashes with rsync. Always test behavior first. Excluded directories are relative to the second-to-last folder of the copy-from arg. Here I am copying the some folder. But in order to exclude folders directly beneath some, I must still reference some in the exclusion. Note the trailing slash at the remote location, which means the some folder is copied into /bk/ rather than replacing the contents of /bk with the contents of some.</description>
      </item>
    
      <item>
        <title>Installing Integr8tly</title>
        <link>https://briantward.github.io/integr8tly-installation/</link>
        <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/integr8tly-installation/</guid>
        <description>Installing Integr8tly TODO: clean up and sort out steps, using container installer
 git clone -b fix-verify-launcher https://github.com/briantward/installation.git oc login ${OCP_MASTER_URL} ansible.cfg id_rsa inventories/hosts ansible -m ping all ansible-playbook -i inventories/hosts playbooks/install.yml pip install jsonpointer     </description>
      </item>
    
      <item>
        <title>Lenovo Intel i915 Video Drivers in Linux, Part 3</title>
        <link>https://briantward.github.io/lenovo-linux-intel-i915-video-part3/</link>
        <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lenovo-linux-intel-i915-video-part3/</guid>
        <description>Lenovo Intel i915 Video Drivers in Linux, Part 3 Problem Scenario/Steps:
Lenovo T460s
thinkpad ultra dock P/N SD20A06046 Type 40A2 S/N M3-A0AC8E 16/11+ fedora 26/27/28/29, according to my records any kernel since 4.15.9-300.fc27.x86_64
  Dock laptop in docking station with two connected monitors, one HDMI and one DVI.
  Undock laptop.
  Redock laptop &amp;#8594; screen failure and system lock until undock again. Leave it long enough and it will reboot itself.</description>
      </item>
    
      <item>
        <title>ElasticSearch on OpenShift</title>
        <link>https://briantward.github.io/elasticsearch/</link>
        <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/elasticsearch/</guid>
        <description>ElasticSearch on OpenShift   Node Tuning
$ sysctl -w vm.max_map_count=262144 $ echo &#34;vm.max_map_count=262144&#34; &amp;gt; /etc/sysctl.d/90-logging.conf   https://github.com/openshift/openshift-ansible/blob/release-3.11/playbooks/openshift-logging/private/config.yml#L94-L116
 https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
   Get indices, run from inside container
curl --key /etc/elasticsearch/secret/admin-key --cert /etc/elasticsearch/secret/admin-cert --cacert /etc/elasticsearch/secret/admin-ca https://localhost:9200/_cat/indices -s     Delete red indices, run from inside container
for i in $(curl --key /etc/elasticsearch/secret/admin-key --cert /etc/elasticsearch/secret/admin-cert --cacert /etc/elasticsearch/secret/admin-ca https://localhost:9200/_cat/indices -s | grep red | awk &#39;{print $3}&#39;); do curl --key /etc/elasticsearch/secret/admin-key --cert /etc/elasticsearch/secret/admin-cert --cacert /etc/elasticsearch/secret/admin-ca https://localhost:9200/$i -X DELETE; done     Explain allocation, frun from inside container</description>
      </item>
    
      <item>
        <title>Red Hat Certified Developer Containers</title>
        <link>https://briantward.github.io/dev-containers/</link>
        <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/dev-containers/</guid>
        <description>Red Hat Certified Developer Containers   registry.redhat.io/rhscl/devtoolset-8-toolchain-rhel7
https://access.redhat.com/containers/#/registry.access.redhat.com/rhscl/devtoolset-8-toolchain-rhel7
Platform for building C/C++ applications using Red Hat Developer Toolset 7. Red Hat Developer Toolset is a Red Hat offering for developers on the Red Hat Enterprise Linux platform. It provides a complete set of development and performance analysis tools that can be installed and used on multiple versions of Red Hat Enterprise Linux. Executables built with the Red Hat Developer Toolset toolchain can then also be deployed and run on multiple versions of Red Hat Enterprise Linux.</description>
      </item>
    
      <item>
        <title>Add SSH key to OpenShift 4</title>
        <link>https://briantward.github.io/add-sshkey-to-ocp4/</link>
        <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/add-sshkey-to-ocp4/</guid>
        <description>Add SSH key to OpenShift 4 To add an SSH key if one was not provided during installation, perform the following from an admin account such as system:admin:
 --- # oc debug node/&amp;lt;NODE_NAME&amp;gt; $ chroot /host $ mkdir /home/core/.ssh $ vi /home/core/.ssh/authorized_keys $ chown core:core -R /home/core/.ssh/ $ chmod 644 /home/core/.ssh/authorized_keys ---   Borrowed from Ryan Howe.
   </description>
      </item>
    
      <item>
        <title>Antivirus on Red Hat Enterprise Linux</title>
        <link>https://briantward.github.io/anti-virus-on-rhel/</link>
        <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/anti-virus-on-rhel/</guid>
        <description>Antivirus on Red Hat Enterprise Linux   Search for Anti-Virus certified on RHEL ecosystem:
https://access.redhat.com/ecosystem/search/#/category/Software?sort=sortTitle%20asc&amp;amp;query=virus&amp;amp;ecosystem=Red%20Hat%20Enterprise%20Linux
  Is any virus protection software needed for Red Hat Enterprise Linux?
https://access.redhat.com/solutions/9203
  Is fanotify supported in Red Hat Enterprise Linux?
https://access.redhat.com/solutions/458193
  Systems become unresponsive due to an issue in the implementation of Fanotify in Red Hat and CentOS 7.x kernels
https://kc.mcafee.com/corporate/index?page=content&amp;amp;id=KB90121&amp;amp;actp=null&amp;amp;viewlocale=en_US&amp;amp;showDraft=false&amp;amp;platinum_status=false&amp;amp;locale=en_US
  System hang due to blocked tasks in fanotify code</description>
      </item>
    
      <item>
        <title>Gluster Tips</title>
        <link>https://briantward.github.io/gluster-tips/</link>
        <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/gluster-tips/</guid>
        <description>Gluster Tips Setting Gluster Up for RHV Host # yum install glusterfs-server -y # service glusterd start # gluster v create vmstore localhost:/your/brick force # gluster v start vmstore # mount -t glusterfs localhost:/vmstore /var/lib/libvirt/images   # gluster v set vmstore group virt   Adjust ownership to qemu user
 # gluster volume set gkvms storage.owner-uid 36 # gluster volume set gkvms storage.owner-gid 36   Stop glusterd. This little bash script ensures it&amp;#8217;s all down.</description>
      </item>
    
      <item>
        <title>Security Pipelines in OpenShift Container Platform</title>
        <link>https://briantward.github.io/security-pipelines/</link>
        <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/security-pipelines/</guid>
        <description>Security Pipelines in OpenShift Container Platform These are random notes for work in progress coded at https://github.com/briantward/container-pipelines/tree/parallel-spring-boot
 - two OCP clusters: nonprod (dev, test, etc) and prod (prod, stage) - allow nonprod cluster to continue pulling image updates automatically to registry - have separate registries between nonprod and prod - new builds only happen in nonprod, never in prod - existing dev pipeline must be aware of possible update to deployed container by alternative parallel pipeline route and keep base image in sync - new security pipeline, parallel to existing dev pipeline: -- poll for updates to images in nonprod cluster --- polling will check similar to what happens when the nonprod cluster syncs from RH Registry --- can we capture a log of the updates from RH registry and just act on them?</description>
      </item>
    
      <item>
        <title>Red Hat Identity Management Server - Missing DNS Record</title>
        <link>https://briantward.github.io/rhidm-missing-dns-record/</link>
        <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rhidm-missing-dns-record/</guid>
        <description>Red Hat Identity Management Server - Missing DNS Record Recently my server lab lost power. Stuff did not come back cleanly, and I needed to get my house back in order.
 My Red Hat Identity Management Server, aka freeipa, running on a RHEL7 machine, restarted along with all the other physicals and vms. When the IdM server came back up, I noticed after some time that it had missing DNS records for some of my machines.</description>
      </item>
    
      <item>
        <title>OpenShift Authenticate all Namespaces to a Secured Registry</title>
        <link>https://briantward.github.io/openshift-auth-all-namespaces-to-a-secured-registry/</link>
        <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-auth-all-namespaces-to-a-secured-registry/</guid>
        <description>OpenShift Authenticate all Namespaces to a Secured Registry If your organization maintains or uses a third-party container registry requiring authentication, this article will help you setup one set of credentials in OpenShift for all your users.
 Implication: all users have access to these credentials. They should be read-only.
 Recently Red Hat launched a new Container Registry at registry.redhat.io requiring authenticated logins. When you install an OpenShift 3.10 or greater cluster, your default pull registry for the images and templates in the OpenShift namespace will use this registry.</description>
      </item>
    
      <item>
        <title>Convert Windows Machine to Windows VM in KVM</title>
        <link>https://briantward.github.io/convert-windows-to-kvm/</link>
        <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/convert-windows-to-kvm/</guid>
        <description>Convert Windows Machine to Windows VM in KVM Export to windows VM
   Disk2vhd v2.01
   Convert to QEMU KVM
   Converting between image formats
  Converting Virtual Machines from Other Hypervisors to KVM with virt-v2v in RHEL 7
   Keyboard was not working initially
   use oskb - on screen keyboard - to enter password or such
  go to control panel &amp;gt; programs</description>
      </item>
    
      <item>
        <title>Convert WMA to MP3</title>
        <link>https://briantward.github.io/convert-wma-to-mp3/</link>
        <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/convert-wma-to-mp3/</guid>
        <description>Convert WMA to MP3 A one liner to convert all WMA files in a directory to MP3
 for file in *.wma; do ffmpeg -i &#34;${file}&#34; -acodec libmp3lame -ab 192k &#34;${file/.wma/.mp3}&#34;; done   From:
   https://askubuntu.com/questions/508278/how-to-use-ffmpeg-to-convert-wma-to-mp3-recursively-importing-from-txt-file
     </description>
      </item>
    
      <item>
        <title>Git Tips</title>
        <link>https://briantward.github.io/git/</link>
        <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/git/</guid>
        <description>Git Tips   When you are required to use git over HTTPS but you don&amp;#8217;t want to be prompted for your credentials every time.
$ git config --global credential.helper cache $ git config credential.helper &#39;cache --timeout=3600&#39;     Set author display on git rebase
$ git config --add rebase.instructionFormat &#34;(%an &amp;lt;%ae&amp;gt;) %s&#34;   https://stackoverflow.com/questions/35851671/is-there-a-way-to-list-the-commits-author-in-git-rebase-i-interactive
      </description>
      </item>
    
      <item>
        <title>OpenShift JBoss EAP</title>
        <link>https://briantward.github.io/openshift-jboss-eap/</link>
        <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-jboss-eap/</guid>
        <description>OpenShift JBoss EAP Logging To update the server on-the-fly, if you are debugging and don&amp;#8217;t want your change to be persistent:
 oc exec $POD_NAME -- /opt/eap/bin/jboss-cli.sh -c &#34;/subsystem=logging/logger=org.keycloak:add(level=TRACE)&#34;   Note that the above requires the server to already be booted. If you are troubleshooting the boot sequence you&amp;#8217;ll need to update the standalone configuration. You may also want changes on a more permanent basis.
  Get the existing configuration:</description>
      </item>
    
      <item>
        <title>Managing Certificates</title>
        <link>https://briantward.github.io/cert-tips/</link>
        <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/cert-tips/</guid>
        <description>Managing Certificates My favorite quick ref:
 https://www.sslshopper.com/article-most-common-openssl-commands.html
 Checking certificates on OpenShift You could just as easily modify this for other applications.
 # cat &amp;lt;&amp;lt; &#39;EOF&#39; &amp;gt;&amp;gt; check-certs.sh #!/bin/bash for filename in `find /etc/origin -name &#34;*.crt*&#34; -o -name &#34;*.pem*&#34; -o -name &#34;*.cer*&#34;` ; do echo $filename; echo &#34; contains&#34; `grep BEGIN $filename | wc -l`; openssl crl2pkcs7 -nocrl -certfile $filename | openssl pkcs7 -print_certs -text -noout | grep -E &#34;</description>
      </item>
    
      <item>
        <title>Regex Tips</title>
        <link>https://briantward.github.io/regex-tips/</link>
        <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/regex-tips/</guid>
        <description>Regex Tips Grab content across lines:
 ((.|\n)*)   My favorite tester:
   https://regex101.com/
     </description>
      </item>
    
      <item>
        <title>Restore Files from rm</title>
        <link>https://briantward.github.io/restore-files-from-rm/</link>
        <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/restore-files-from-rm/</guid>
        <description>Restore files from rm I wanted to type:
 $ rm *.retry   Instead I accidentally typed:
 $ rm * .retry   That wiped out the four or five files I had been working on the last two days. I was lucky it wasn&amp;#8217;t more. I was lucky I didn&amp;#8217;t care about the binary data I had in the folder. It took a little time and work, but in the end, I was able to find all the documents.</description>
      </item>
    
      <item>
        <title>Red Hat Virtualization Tips</title>
        <link>https://briantward.github.io/rhv-tips/</link>
        <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rhv-tips/</guid>
        <description>Red Hat Virtualization Tips Set up a user who can run virsh list --all
 saslpasswd2 -a libvirt username     </description>
      </item>
    
      <item>
        <title>Configuring an External Heketi Prometheus Monitor on OpenShift</title>
        <link>https://briantward.github.io/openshift-prometheus-external-heketi/</link>
        <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-prometheus-external-heketi/</guid>
        <description>Configuring an External Heketi Prometheus Monitor on OpenShift Kudos goes to Ido Braunstain at devops.college for doing this on a raw Kubernetes cluster to monitor a GPU node. I adapted my information from his article to apply to monitoring both heketi and my external gluster nodes.
 Install the node-exporter on the external host First install docker to run the node-exporter container. You may want to consider configuring other docker options.</description>
      </item>
    
      <item>
        <title>Lenovo Intel i915 Video Drivers in Linux, Part 2</title>
        <link>https://briantward.github.io/lenovo-linux-intel-i915-video-part2/</link>
        <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lenovo-linux-intel-i915-video-part2/</guid>
        <description>Lenovo Intel i915 Video Drivers in Linux, Part 2 Problem Scenario/Steps:
Lenovo T460s
thinkpad ultra dock P/N SD20A06046 Type 40A2 S/N M3-A0AC8E 16/11+ fedora 26/27/28/29, according to my records any kernel since 4.15.9-300.fc27.x86_64
  Dock laptop in docking station with two connected monitors, one HDMI and one DVI.
  Undock laptop.
  Redock laptop &amp;#8594; screen failure and system lock until undock again. Leave it long enough and it will reboot itself.</description>
      </item>
    
      <item>
        <title>Image Video Metadata</title>
        <link>https://briantward.github.io/image-video-metadata/</link>
        <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/image-video-metadata/</guid>
        <description>Image Video Metadata Tips My wife and I wanted to combine photos and videos from my Samsung S7 and her iPhone 6. Apple has a nice app that compiles photos and videos with background music, but doesn&amp;#8217;t give you a lot of customization options. We couldn&amp;#8217;t sort except by date. Since we wanted one particular photo at the end, we figured we would just hack the create date to trick it.</description>
      </item>
    
      <item>
        <title>Ansible Tips</title>
        <link>https://briantward.github.io/ansible-tips/</link>
        <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/ansible-tips/</guid>
        <description>Ansible Tips Print to stout and log at same time&amp;#8230;&amp;#8203; ansible-playbook -i hosts playbook.yml -vvv | tee -a output.log    Run a single command on all hosts&amp;#8230;&amp;#8203; this one cleans up your journals&amp;#8230;&amp;#8203; and runs 10 at a time ansible all -a &#39;journalctl --vacuum-time=2d&#39; -f 10      </description>
      </item>
    
      <item>
        <title>OpenShift Remove Stuck ServiceInstance</title>
        <link>https://briantward.github.io/openshift-remove-stuck-serviceinstance/</link>
        <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-remove-stuck-serviceinstance/</guid>
        <description>OpenShift Remove Stuck ServiceInstance To delete a stuck serviceinstance where a project namespace no longer exists:
 $ oc get serviceinstance --all-namespaces -o wide NAMESPACE NAME CLASS PLAN STATUS AGE test cakephp-mysql-example-vfzkq ClusterServiceClass/cakephp-mysql-example default Failed 113d test cakephp-mysql-persistent-f75gl ClusterServiceClass/cakephp-mysql-persistent default Failed 113d webconsole-extensions httpd-example-6fxx5 ClusterServiceClass/httpd-example default DeprovisionCallFailed 10d    Create the project namespace again
$ oc new-project test     Now delete the serviceinstance
$ oc delete serviceinstance test -n cakephp-mysql-example-vfzkq     If that doesn&amp;#8217;t delete it, then remove the finalizer</description>
      </item>
    
      <item>
        <title>OpenShift Reissue Certificate Manually</title>
        <link>https://briantward.github.io/openshift-reissue-certificate-manually/</link>
        <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-reissue-certificate-manually/</guid>
        <description>OpenShift Reissue Certificate Manually I recently ran the redeploy certificates playbook on my 3.11 cluster and found it broke apps that rely on the certificate signer ca, as it issues a new certificate signer ca but does not retrigger new certificates to be generated from it (at least not for all of the apps). In my case, it killed the latest Prometheus deployment and I got service unavailable messages from the router.</description>
      </item>
    
      <item>
        <title>Cgroups, cAdvisor, heapster, hawkular, and docker memory statistics in OpenShift</title>
        <link>https://briantward.github.io/memory-in-openshift/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/memory-in-openshift/</guid>
        <description>Cgroups, cAdvisor, heapster, hawkular, and docker memory statistics in OpenShift Work In Progress
 memory.usage_in_bytes # show current usage for memory (See 5.5 for details) memory.memsw.usage_in_bytes # show current usage for memory+Swap (See 5.5 for details)   memory.stat file includes following statistics
   per-memory cgroup local status cache - # of bytes of page cache memory. rss - # of bytes of anonymous and swap cache memory (includes transparent hugepages).</description>
      </item>
    
      <item>
        <title>OpenShift HTTPD loglevel</title>
        <link>https://briantward.github.io/openshift-httpd-loglevel/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-httpd-loglevel/</guid>
        <description>OpenShift HTTPD loglevel OpenShift comes with a container image packaged from this source. To make further configuration changes check the documentation here.
 https://github.com/sclorg/httpd-container
  Create a configmap to mount a log.conf file that contains your apache loglevel configuration. Be sure to update &amp;lt;PROJECT_NAMESPACE&amp;gt; below before running this command.
   echo &#39;apiVersion: v1 data: log.conf: | LogLevel debug ErrorLog /dev/stdout TransferLog /dev/stdout&#39; kind: ConfigMap metadata: name: logfile namespace: &amp;lt;PROJECT_NAMESPACE&amp;gt;&#39; | oc create -f -    Update your deploymentConfig.</description>
      </item>
    
      <item>
        <title>OpenShift Project Backup and Migration Strategies</title>
        <link>https://briantward.github.io/openshift-backup-migration/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-backup-migration/</guid>
        <description>OpenShift Project Backup and Migration Strategies Work In Progress
 export
 secret bc is dc service route pv pvc
 remove (cinder) annotations for pv and pvc because it checks them
 replicate storage backend in new snapshot
   </description>
      </item>
    
      <item>
        <title>OpenShift Prometheus Node Exporter CrashLoop</title>
        <link>https://briantward.github.io/openshift-prometheus-node-exporter-crashloop/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-prometheus-node-exporter-crashloop/</guid>
        <description>OpenShift Prometheus Node Exporter CrashLoop Issue: A prometheus node exporter pod is stuck in a CrashLoopBackOff as a result of a failure to release the port 9100 bound by the previous instance before the next instance starts and attempts to reattach to it. This could potentially be resolved by changing the daemonset configuration (updateStrategy or terminationGracePeriodSeconds). Here, since we&amp;#8217;ve only seen it once, we just kill the process holding the port open from the node itself.</description>
      </item>
    
      <item>
        <title>OpenShift Update Router Fix</title>
        <link>https://briantward.github.io/openshift-update-router-fix/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-update-router-fix/</guid>
        <description>OpenShift Update Router Fix Updating from v3.11.0 to v3.11.51 introduced a new volume mount on the router that did not previously exist (or maybe something wonky just happened in my cluster).
 Log message on router pod attempting to spin up. If you don&amp;#8217;t have one attempting to spin up now (i.e. it failed a while back and just rolled back to the previous ReplicationController), delete the latest ReplicationController (not the one running the good pods!</description>
      </item>
    
      <item>
        <title>Terminal to File Tips</title>
        <link>https://briantward.github.io/terminal-to-file/</link>
        <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/terminal-to-file/</guid>
        <description>Terminal to File Tips cat &amp;lt;&amp;lt;EOF | kubectl create -f - apiVersion: v1 kind: ServiceAccount metadata: name: heapster EOF   echo &#39;apiVersion: v1 data: &amp;lt;FILENAME&amp;gt;: | &amp;lt;FILECONTENT&amp;gt; kind: ConfigMap metadata: name: &amp;lt;CONFIGMAP_NAME&amp;gt; namespace: &amp;lt;PROJECT_NAMESPACE&amp;gt;&#39; | oc create -f -     </description>
      </item>
    
      <item>
        <title>Migrate OpenShift PersistentVolumes from One Cluster to Another</title>
        <link>https://briantward.github.io/openshift-migrate-pv/</link>
        <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-migrate-pv/</guid>
        <description>Migrate OpenShift PersistentVolumes from One Cluster to Another Work In Progress!
 $ oc get pv mypvid -o yaml --export &amp;gt; mypv.yaml $ oc get pvc mypvcid -o yaml --export &amp;gt; mypvc.yaml   Remove all annotations and instance identifiers. If you leave them in place, you may get an error stating the PVC is lost.
 Verify that all SecurityContextContstraints are the same between each cluster and project environment, otherwise you may fail to gain ownership of the volume.</description>
      </item>
    
      <item>
        <title>OpenShift Web Console Extensions</title>
        <link>https://briantward.github.io/openshift-web-console-extensions/</link>
        <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-web-console-extensions/</guid>
        <description>OpenShift Web Console Extensions Testing Environment: OpenShift 3.11
Applicable Environment: OpenShift 3.9+
 As of OpenShift 3.9, the web console requires URL references rather than static content directories.[1]
 In OpenShift 3.7 and lower, you could mount static files from your masters through the master-config.yaml file.[2] Since this no longer applies, we have to provide our own webserver with the content, to be referenced by the web console pod remotely. I checked for ways to mount static files to the web console pod; however, in the new design there is no static directory location within the pod itself from which it could reference such files.</description>
      </item>
    
      <item>
        <title>Automatically Update Red Hat Container Images on OpenShift 3.11</title>
        <link>https://briantward.github.io/sync-redhat-images-on-openshift-311/</link>
        <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/sync-redhat-images-on-openshift-311/</guid>
        <description>Automatically Update Red Hat Container Images on OpenShift 3.11 OpenShift manages container images using a registry. This is the place where it caches upstream container images and stores the images from your own builds as well. Each build or container image correlates to an ImageStream, which is an object that defines any number of related images by tags. For example, one specific version of a Ruby container might be v2.5-22, but you can have one ImageStream definition that holds ruby tags and correlating images for v2.</description>
      </item>
    
      <item>
        <title>OpenShift Image Management</title>
        <link>https://briantward.github.io/openshift-image-management/</link>
        <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/openshift-image-management/</guid>
        <description>OpenShift Image Management $ oc project openshift Now using project &#34;openshift&#34; on server &#34;https://openshift.example.com:8443&#34;. $ oc get is | grep php NAME DOCKER REPO TAGS UPDATED php docker-registry.default.svc:5000/openshift/php 7.1,latest,5.6 + 2 more... 11 days ago   $ oc import-image registry.access.redhat.com/rhscl/php-70-rhel7:7.0-17 --confirm The import completed successfully. Name:	php-70-rhel7 Namespace:	openshift Created:	Less than a second ago Labels:	&amp;lt;none&amp;gt; Annotations:	openshift.io/image.dockerRepositoryCheck=2018-08-15T18:38:10Z Docker Pull Spec:	docker-registry.default.svc:5000/openshift/php-70-rhel7 Image Lookup:	local=false Unique Images:	1 Tags:	1 7.</description>
      </item>
    
      <item>
        <title>Performance and Benchmarking</title>
        <link>https://briantward.github.io/performance-and-benchmarking/</link>
        <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/performance-and-benchmarking/</guid>
        <description>Performance and Benchmarking Are there any benchmarking and performance testing tools available in Red Hat Enterprise Linux?
   </description>
      </item>
    
      <item>
        <title>oc Tips</title>
        <link>https://briantward.github.io/oc-tips/</link>
        <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/oc-tips/</guid>
        <description>OC Command Tips $ oc login -u system:admin   $ oc whoami --config=$HOME/.kube/config   Show all resources&amp;#8230;&amp;#8203; and I mean ALL:
 $ kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n openshift-monitoring     </description>
      </item>
    
      <item>
        <title>oc Tips</title>
        <link>https://briantward.github.io/oc-tips/</link>
        <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/oc-tips/</guid>
        <description>OC Command Tips $ oc login -u system:admin   $ oc whoami --config=$HOME/.kube/config   Show all resources&amp;#8230;&amp;#8203; and I mean ALL:
 $ kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n openshift-monitoring   Show docker images on node for each node found in pods listing. (Thanks Todd Penn)
 $ for node in $(oc get pods -o jsonpath=&#39;{range .items[*].spec}{.nodeName}{&#34; &#34;}{end}&#39;); do echo $node; ssh $node &#34;</description>
      </item>
    
      <item>
        <title>Java on RHEL / Centos / Fedora</title>
        <link>https://briantward.github.io/java-on-rhel/</link>
        <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/java-on-rhel/</guid>
        <description>Java on RHEL / Centos / Fedora $ ls -lah /usr/lib/jvm total 20K drwxr-xr-x. 5 root root 4.0K Jul 30 09:56 . dr-xr-xr-x. 51 root root 4.0K Jul 20 12:02 .. lrwxrwxrwx. 1 root root 26 Jul 30 09:56 java -&amp;gt; /etc/alternatives/java_sdk lrwxrwxrwx. 1 root root 32 Jul 30 09:56 java-1.8.0 -&amp;gt; /etc/alternatives/java_sdk_1.8.0 lrwxrwxrwx. 1 root root 40 Jul 30 09:56 java-1.8.0-openjdk -&amp;gt; /etc/alternatives/java_sdk_1.8.0_openjdk drwxr-xr-x. 3 root root 4.0K Mar 29 10:21 java-1.</description>
      </item>
    
      <item>
        <title>Gnome Session</title>
        <link>https://briantward.github.io/gnome-session/</link>
        <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/gnome-session/</guid>
        <description>Gnome Session Show whether you are on wayland or x11: $ loginctl show-session $(loginctl | grep $(whoami) | awk &#39;{print $1}&#39;) -p Type   or
 $ echo $XDG_SESSION_TYPE    Switch gui terminal ctrl + alt + f1    Restart You can restart the gnome-shell by pressing Alt+F2 and then typing in either &#34;restart&#34; or just &#34;r&#34; and pressing enter.
  Software Center History This app, gnome-software is sorta nice in its GUI flashiness and reminds me of Apple app store.</description>
      </item>
    
      <item>
        <title>YUM DNF Tips</title>
        <link>https://briantward.github.io/yum-dnf-tips/</link>
        <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/yum-dnf-tips/</guid>
        <description>YUM and DNF Tips Remove all cache $ rm -rf /var/cache/yum      </description>
      </item>
    
      <item>
        <title>Import Images with dockerImageRepository</title>
        <link>https://briantward.github.io/import-images-with-dockerimagerepository/</link>
        <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/import-images-with-dockerimagerepository/</guid>
        <description>Import Images with dockerImageRepository $ echo &#39;apiVersion: v1 &amp;gt; kind: ImageStream &amp;gt; metadata: &amp;gt; creationTimestamp: null &amp;gt; generation: 2 &amp;gt; labels: &amp;gt; build: is-test &amp;gt; name: jenkins-slave-base-centos7 &amp;gt; spec: &amp;gt; dockerImageRepository: docker.io/openshift/jenkins-slave-base-centos7&#39; | oc apply -f- imagestream &#34;jenkins-slave-base-centos7&#34; created [esauer@localhost image-scanning]$ oc export is jenkins-slave-base-centos7 apiVersion: v1 kind: ImageStream metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&#34;apiVersion&#34;:&#34;v1&#34;,&#34;kind&#34;:&#34;ImageStream&#34;,&#34;metadata&#34;:{&#34;annotations&#34;:{},&#34;creationTimestamp&#34;:null,&#34;generation&#34;:2,&#34;labels&#34;:{&#34;build&#34;:&#34;is-test&#34;},&#34;name&#34;:&#34;jenkins-slave-base-centos7&#34;,&#34;namespace&#34;:&#34;sbx-esauer&#34;},&#34;spec&#34;:{&#34;dockerImageRepository&#34;:&#34;docker.io/openshift/jenkins-slave-base-centos7&#34;}} openshift.io/image.dockerRepositoryCheck: 2018-07-25T13:47:59Z creationTimestamp: null generation: 2 labels: build: is-test name: jenkins-slave-base-centos7 spec: dockerImageRepository: docker.io/openshift/jenkins-slave-base-centos7 lookupPolicy: local: false tags: - annotations: null from: kind: DockerImage name: docker.</description>
      </item>
    
      <item>
        <title>Sync Red Hat Container Images on OpenShift 3.9</title>
        <link>https://briantward.github.io/sync-redhat-images-on-openshift-39/</link>
        <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/sync-redhat-images-on-openshift-39/</guid>
        <description>Sync Red Hat Container Images on OpenShift 3.9 If using the default Advanced Installer, and setting the flag to deploy openshift_install_examples [1] in your cluster (or using the default which is true), you will find that the ansible installer adds some nice stuff to your local registry from the openshift_examples [2] folder.
 $ oc get is -n openshift NAME DOCKER REPO TAGS UPDATED imagestreams/eap71-openshift docker-registry.default.svc:5000/openshift/eap71-openshift latest 3 months ago imagestreams/httpd docker-registry.</description>
      </item>
    
      <item>
        <title>Attach a Specific Subscription Pool to a RHEL Machine</title>
        <link>https://briantward.github.io/rhel-subscription-manager-pool-id/</link>
        <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/rhel-subscription-manager-pool-id/</guid>
        <description>Attach a Specific Subscription Pool to a RHEL Machine subscription-manager list --all --available --matches=&#34;OpenShift Container Platform&#34; | awk &#39;/Pool ID/ {print $3}&#39; | head -1 subscription-manager attach --pool=$(subscription-manager list --all --available --matches=&#34;OpenShift Container Platform&#34; | awk &#39;/Pool ID/ {print $3}&#39; | head -1)     </description>
      </item>
    
      <item>
        <title>Configure Dell PowerConnect PC5324</title>
        <link>https://briantward.github.io/configure-dell-powerconnect-pc5324/</link>
        <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/configure-dell-powerconnect-pc5324/</guid>
        <description>Configure Dell PowerConnect PC5324 Followed help from these sites   https://www.stevejenkins.com/blog/2011/05/dell-powerconnect-5324-setup-tasks/
  http://ninjix.blogspot.com/2013/03/dell-powerconnect-serial-console-on.html
    Tools to connect to console Minicom
   can be a problem if the env variable TERM is not set correctly.
  hit enter. then cntl-A then q then enter to exit minicom.
   screen
   Use the screen quit command (normally ctrl-A \).
    Steps taken  Downloaded latest firmware</description>
      </item>
    
      <item>
        <title>Helpful Filesystem Tips</title>
        <link>https://briantward.github.io/filesystems/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/filesystems/</guid>
        <description>Helpful Filesystem Tips   change reserved space on ext4 partitions to zero. Useful for drives specifically for data storage and no system recovery needed.
# tune2fs -m 0 /dev/sdb1     print UUID of filesystems
# blkid     remount a readonly filesystem to rewrite
# mount -o remount,rw /     watch the status of dd (useful on systems without &#34;status=progress&#34;, like Mac I think)</description>
      </item>
    
      <item>
        <title>Lenovo Linux Power Configuration T460s</title>
        <link>https://briantward.github.io/lenovo-linux-power/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lenovo-linux-power/</guid>
        <description>Lenovo Linux Power Configuration T460s /etc/UPower/UPower.conf CriticalPowerAction=Hibernate
   </description>
      </item>
    
      <item>
        <title>Let&#39;s Encrypt on OpenShift</title>
        <link>https://briantward.github.io/lets-encrypt-on-openshift/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lets-encrypt-on-openshift/</guid>
        <description>Let&amp;#8217;s Encrypt on OpenShift Updated OS on load balancer
 # wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm # yum install epel-release-latest-7.noarch.rpm   Uses python:
   https://www.redpill-linpro.com/sysadvent/2017/12/15/letsencrypt-on-openshift.html
  https://certbot.eff.org/about/
   Uses bash: - https://blog.openshift.com/lets-encrypt-acme-v2-api/ - https://github.com/Neilpang/acme.sh#currently-acmesh-supports
   https://community.letsencrypt.org/t/acme-v2-and-wildcard-certificate-support-is-live/55579
  https://www.namecheap.com/
   Other:
   https://github.com/certbot/certbot/issues/5074
  https://github.com/freeipa/freeipa-letsencrypt
  https://github.com/antevens/letsencrypt-freeipa
  https://certbot.eff.org/docs/using.html#dns-plugins
     </description>
      </item>
    
      <item>
        <title>Navigating Linux</title>
        <link>https://briantward.github.io/navigating-linux/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/navigating-linux/</guid>
        <description>Navigating Linux   Move a file to different extension, or change parts of a name
$ mv /etc/yum.repos.d/redhat.{repo,disabled}     Search for all mac dot underscore files
$ find -name ._\* $ find -name .DS_Store $ find -name .DS_Store -delete     find and replace text in files in a directory, recursively:
$ find /directory -type f -print0 | xargs -0 sed -i &#39;s/old-text/new-text/g&#39;        </description>
      </item>
    
      <item>
        <title>Networking tips</title>
        <link>https://briantward.github.io/networking/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/networking/</guid>
        <description>Networking Tips Find the eth0 ip addr ETH0_IP=`ifconfig eth0 2&amp;gt;/dev/null | awk &#39;/inet addr:/ {print $2}&#39; | sed &#39;s/addr://&#39;`    troubleshooting NIC # lspci -nn | grep Ethernet # lspci -k -d ::0200   where,
-nn: Show PCI vendor and device codes as both numbers and names.
-k: Show driver information for a device.
-d: Filter on just the &#39;Ethernet&#39; device class (0200)
  Check Kernel module load # dmesg | grep e1000e   (kernel module e1000e found above)</description>
      </item>
    
      <item>
        <title>VIM Tips</title>
        <link>https://briantward.github.io/vim/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/vim/</guid>
        <description>VIM Tips   Set YAML filetypes to have two spaces on indent
$ echo &#34;autocmd FileType yaml,yml setlocal ai ts=2 sw=2 et&#34; &amp;gt;&amp;gt; ~/.vimrc     write with sudo when it wasn&amp;#8217;t opened with sudo:
:w !sudo tee %        </description>
      </item>
    
      <item>
        <title>XML Tips</title>
        <link>https://briantward.github.io/xml/</link>
        <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/xml/</guid>
        <description>XML Tips   Format raw xml on the cli
echo &#39;&amp;lt;root&amp;gt;&amp;lt;foo a=&#34;b&#34;&amp;gt;lorem&amp;lt;/foo&amp;gt;&amp;lt;bar value=&#34;ipsum&#34; /&amp;gt;&amp;lt;/root&amp;gt;&#39; | xmllint --format -        </description>
      </item>
    
      <item>
        <title>Lenovo BIOS/UEFI update via USB from Linux</title>
        <link>https://briantward.github.io/lenovo-linux-bios-update/</link>
        <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lenovo-linux-bios-update/</guid>
        <description>I&amp;#8217;m on a Lenovo T460s running fedora 27. One day, I ran into an issue with my video setup. It occurred to me that I had not updated my bios in a while, and since the whole Meltdown/Spectre thing came up, I should probably check on this. Yes, sure enough, I was on patch 1.20, the latest was 1.34, and the fix for Meltdown/Spectre was in 1.31. Good thing no one cares about my machine but me.</description>
      </item>
    
      <item>
        <title>Lenovo Intel i915 Video Drivers in Linux</title>
        <link>https://briantward.github.io/lenovo-linux-intel-i915-video/</link>
        <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/lenovo-linux-intel-i915-video/</guid>
        <description>Note: Out of Date and incorrect analysis.
 I&amp;#8217;m running fedora 27 on my Lenovo T460s and have been for a while. I have a docking station with two 24&#34; monitors at work and another docking station with two 27&#34; monitors at home. I switch between them frequently. Back in fedora 21 and 22 I had tons of problems. Sometimes monitors didn&amp;#8217;t come on, sometimes one monitor came on, and sometimes things worked fine.</description>
      </item>
    
      <item>
        <title>SSH-Agent</title>
        <link>https://briantward.github.io/ssh-agent/</link>
        <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/ssh-agent/</guid>
        <description>Every now and then for some reason my ssh-agent does work by default on startup. I have to reach out to this lovely stackoverflow to remember such a simple command:
 exec ssh-agent bash ssh-add ~/.ssh/*   alternatively
 eval `ssh-agent -s` ssh-add ~/.ssh/*   https://stackoverflow.com/questions/17846529/could-not-open-a-connection-to-your-authentication-agent
 </description>
      </item>
    
      <item>
        <title>Hugo Blog on OpenShift</title>
        <link>https://briantward.github.io/hugo-blog-on-openshift/</link>
        <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
        <guid>https://briantward.github.io/hugo-blog-on-openshift/</guid>
        <description>Create a Dockerfile that adds all the dependencies your environment needs. A lot of the work is in this Dockerfile. I used asciidocs, so I needed an implementation of either asciidoc or asciidoctor, the two options that Hugo provides integration with. I chose asciidoctor.
   $ cat Dockerfile FROM centos:centos7 COPY . /opt/blog RUN cd /opt \ &amp;amp;&amp;amp; curl -O -J -L https://github.com/gohugoio/hugo/releases/download/v0.40.3/hugo_0.40.3_Linux-64bit.tar.gz \ &amp;amp;&amp;amp; tar -xf hugo_0.</description>
      </item>
    
      <item>
        <title>Authenticate Openshift Console with RH-SSO</title>
        <link>https://briantward.github.io/rh-sso-authenticating-openshift-console/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-authenticating-openshift-console/</guid>
        <description>Authenticate Openshift Console with RH-SSO Install based on OpenShift 3.7. Will probably work on other similar versions.
 Be aware of default permissions on your platform.
   https://docs.openshift.com/container-platform/3.7/admin_solutions/user_role_mgmt.html#determine-default-user-roles
   Be aware of the implications of using Google as an Identity Broker.
 Master and Node Configuration:
   https://docs.openshift.com/container-platform/3.7/admin_solutions/master_node_config.htmli
   Here is a great step-by-step example workflow in Red Hat official documentation:
   https://access.</description>
      </item>
    
      <item>
        <title>Configure Google OIDC</title>
        <link>https://briantward.github.io/configure-google-oidc/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/configure-google-oidc/</guid>
        <description>Configure Google OIDC https://console.cloud.google.com
 Since this topic has been well handled by the Keycloak team, I&amp;#8217;m adding there documentation here.
   https://www.keycloak.org/docs/3.4/server_admin/index.html#google
     </description>
      </item>
    
      <item>
        <title>Configure RH-SSO to Identity Broker with Google by Hosted Domain</title>
        <link>https://briantward.github.io/rh-sso-google-oidc/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-google-oidc/</guid>
        <description>Configure RH-SSO to Identity Broker with Google by Hosted Domain In a browser, go to your RH-SSO admin console. This should be your hostname with context /auth/admin, e.g. https://sso.apps.example.com/auth/admin/
 Login with the username and password you set in your template for fields:
 SSO_ADMIN_USERNAME=admin SSO_ADMIN_PASSWORD=redacted   First, create a new realm for your OpenShift users. Out of the box, RH-SSO is configured with a master realm, but this should only be used for administration of the RH-SSO server itself.</description>
      </item>
    
      <item>
        <title>Install RH-SSO on Openshift</title>
        <link>https://briantward.github.io/rh-sso-on-openshift/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-on-openshift/</guid>
        <description>Install RH-SSO on Openshift First create a new project to keep RH-SSO work clean and easily delete it if necessary.
 oc new-project sso   I started by exporting the existing RH-SSO persistent depoyment template. This builds up one RH-SSO app with one postgres persistent database by default. You&amp;#8217;ve got lots of other choices.
 $ oc get template -n openshift | grep sso eap64-sso-s2i An example EAP 6 Single Sign-On application.</description>
      </item>
    
      <item>
        <title>Install a Quickstart App on Openshift Authenticated by RH-SSO</title>
        <link>https://briantward.github.io/rh-sso-openshift-quickstart/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-openshift-quickstart/</guid>
        <description>Install a Quickstart App on Openshift Authenticated by RH-SSO You will need to build and run an app and configure the client in RH-SSO.
 $ oc get template -n openshift | grep sso eap64-sso-s2i An example EAP 6 Single Sign-On application. For more information about using... 44 (19 blank) 8 eap70-sso-s2i An example EAP 7 Single Sign-On application. For more information about using... 44 (19 blank) 8 eap71-sso-s2i An example EAP 7 Single Sign-On application.</description>
      </item>
    
      <item>
        <title>RH-SSO Authentication on Openshift Series</title>
        <link>https://briantward.github.io/rh-sso-on-ocp-series/</link>
        <pubDate>Wed, 09 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-on-ocp-series/</guid>
        <description>RH-SSO Authentication on Openshift Series This is a multi-part series on RH-SSO.
  Install RH-SSO on Openshift
  Install a Quickstart App on Openshift Authenticated by RH-SSO
  Configure Google OIDC
  Configure RH-SSO to Identity Broker with Google by Hosted Domain
  Authenticate Openshift Console with RH-SSO
     </description>
      </item>
    
      <item>
        <title>RH-SSO 7.2 on Red Hat Enterprise Linux 7.5 integrated with Identity Management or Directory Server</title>
        <link>https://briantward.github.io/rh-sso-on-rhel7/</link>
        <pubDate>Tue, 01 May 2018 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/rh-sso-on-rhel7/</guid>
        <description>RH-SSO server install. This can be done with yum/rpm or zip. Using zips allows you to leverage more middleware services on one VM/box. $ unzip rh-sso-7.2.0.GA.zip $ cd rh-sso-7.2/bin $ ./add-user-keycloak.sh -u admin -p admin     EAP server install. $ jboss-eap-7.1.0.zip $ cd jboss-eap-7.1 $ unzip rh-sso-7.2.0.GA-eap7-adapter.zip -d jboss-eap-7.1 $ unzip -o rh-sso-7.2.0.GA-saml-eap7-adapter.zip -d jboss-eap-7.1 $ cd bin $ ./standalone.sh &amp;amp; ENTER $ ./jboss-cli.sh -c --file=adapter-install.cli $ .</description>
      </item>
    
      <item>
        <title>Split DNS Resolution with VPN DNS and Local DNS</title>
        <link>https://briantward.github.io/split-dns-vpn-local-dnsmasq/</link>
        <pubDate>Tue, 01 May 2018 10:40:00 -0400</pubDate>
        <guid>https://briantward.github.io/split-dns-vpn-local-dnsmasq/</guid>
        <description>Split DNS Resolution with VPN DNS and Local DNS Edit 2019-05-16: This work is superceded by this wonderful feature in NetworkManager now:
   https://fedoramagazine.org/using-the-networkmanagers-dnsmasq-plugin/
   Note: does not work as expected. Trouble with connecting to different wireless networks, as each one needs manual tweak. Need a better solution.
 I recently installed a local identity management server with Red Hat Identity Management. This is essentially a free-ipa server that hosts some certificate management, DNS, and LDAP to track both my machines and my users on my local network.</description>
      </item>
    
      <item>
        <title>Securing Red Hat JBoss Web Server 3.X</title>
        <link>https://briantward.github.io/jws-secured/</link>
        <pubDate>Thu, 29 Jun 2017 12:00:00 -0400</pubDate>
        <guid>https://briantward.github.io/jws-secured/</guid>
        <description>Securing Red Hat JBoss Web Server 3.X (configured on 3.0.3 but should be good for 3.1 as well)
 THIS CONFIGURATION HAS NOT BEEN TESTED! THIS IS INTENDED AS A STARTING GUIDE ONLY.
 RPM Base Installation  Register your machine if you have not done so.
# subscription-manager register     List the available subscriptions you have. Look for the Pool ID of your JBoss Web Server subscription</description>
      </item>
    
  </channel>
</rss>
